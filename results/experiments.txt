Test 3: lr = 5e-5, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3
Test 4: lr = 5e-7, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3
Test 5: lr = 5e-4, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 5
Test 7: lr = 5e-7, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 5

Test 8: lr = 5e-4, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 4
Test 6: lr = 5e-7, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 4

Test 9: lr = 5e-4, batch_size = 2 on each GPU, 6 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 2
Test 10: lr = 5e-5, batch_size = 2 on each GPU, 6 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 2
Test 11: lr = 5e-7, batch_size = 2 on each GPU, 6 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 2


Imerg
Test 1: lr = 5e-4, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 1
Test 2: lr = 5e-4, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 2
Test 3: lr = 5e-5, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 1
Test 4: lr = 5e-5, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 2
Test 5: lr = 5e-7, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 1
Test 6: lr = 5e-7, batch_size = 2 on each GPU, 7 GPUS, deepspeed_level = 2, early_stopping patience = 3, accumulate_grad_batches = 2

_IncompatibleKeys(missing_keys=['net.var_embed', 'net.time_pos_embed', 'net.time_query', 'net.token_embeds.0.proj.weight', 'net.token_embeds.0.proj.bias', 'net.token_embeds.1.proj.weight', 'net.token_embeds.1.proj.bias', 'net.token_embeds.2.proj.weight', 'net.token_embeds.2.proj.bias', 'net.token_embeds.3.proj.weight', 'net.token_embeds.3.proj.bias', 'net.token_embeds.4.proj.weight', 'net.token_embeds.4.proj.bias', 'net.token_embeds.5.proj.weight', 'net.token_embeds.5.proj.bias', 'net.token_embeds.6.proj.weight', 'net.token_embeds.6.proj.bias', 'net.token_embeds.7.proj.weight', 'net.token_embeds.7.proj.bias', 'net.token_embeds.8.proj.weight', 'net.token_embeds.8.proj.bias', 'net.token_embeds.9.proj.weight', 'net.token_embeds.9.proj.bias', 'net.token_embeds.10.proj.weight', 'net.token_embeds.10.proj.bias', 'net.token_embeds.11.proj.weight', 'net.token_embeds.11.proj.bias', 'net.token_embeds.12.proj.weight', 'net.token_embeds.12.proj.bias', 'net.token_embeds.13.proj.weight', 'net.token_embeds.13.proj.bias', 'net.token_embeds.14.proj.weight', 'net.token_embeds.14.proj.bias', 'net.token_embeds.15.proj.weight', 'net.token_embeds.15.proj.bias', 'net.token_embeds.16.proj.weight', 'net.token_embeds.16.proj.bias', 'net.token_embeds.17.proj.weight', 'net.token_embeds.17.proj.bias', 'net.token_embeds.18.proj.weight', 'net.token_embeds.18.proj.bias', 'net.token_embeds.19.proj.weight', 'net.token_embeds.19.proj.bias', 'net.token_embeds.20.proj.weight', 'net.token_embeds.20.proj.bias', 'net.token_embeds.21.proj.weight', 'net.token_embeds.21.proj.bias', 'net.token_embeds.22.proj.weight', 'net.token_embeds.22.proj.bias', 'net.token_embeds.23.proj.weight', 'net.token_embeds.23.proj.bias', 'net.token_embeds.24.proj.weight', 'net.token_embeds.24.proj.bias', 'net.token_embeds.25.proj.weight', 'net.token_embeds.25.proj.bias', 'net.token_embeds.26.proj.weight', 'net.token_embeds.26.proj.bias', 'net.head.0.weight', 'net.head.0.bias', 'net.head.2.weight', 'net.head.2.bias', 'net.head.4.weight', 'net.head.4.bias', 'net.time_agg.in_proj_weight', 'net.time_agg.in_proj_bias', 'net.time_agg.out_proj.weight', 'net.time_agg.out_proj.bias'], unexpected_keys=[])
